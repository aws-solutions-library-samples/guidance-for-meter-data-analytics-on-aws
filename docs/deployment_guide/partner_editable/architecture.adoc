:xrefstyle: short

Deploying this QuickStart with default parameters builds the following {partner-product-short-name} environment in the
AWS Cloud.

// Replace this example diagram with your own. Follow our wiki guidelines: https://w.amazon.com/bin/view/AWS_Quick_Starts/Process_for_PSAs/#HPrepareyourarchitecturediagram. Upload your source PowerPoint file to the GitHub {deployment name}/docs/images/ directory in its repository.

[#architecture1]
.QuickStart architecture for {partner-product-short-name} on AWS
image::../images/architecture/MDAv2_architecture_overview.svg[Architecture,width=100%,height=100%]

As shown in <<architecture1>>, the QuickStart sets up the following:

* An extract, transform, load (ETL) pipeline:
** S3 buckets to store data from the meter source system. Staging and Integrated data are stored in separate S3 buckets.
** An AWS Glue workflow:
*** Crawlers, jobs, and triggers to crawl, transform, and convert incoming raw meter data into clean data in the desired format and partitioned business data.
*** Data Catalog to store metadata and source information about the meter data.

* Amazon EventBridge which receives an event as soon as late dater are detected on ingestion

* An ML pipeline:
** AWS Step Functions workflows:
*** Batch processing, which uses the partitioned business data and the data from the model as a basis for forecasting.
*** Model training, which uses the partitioned business data to build an ML model.
** Amazon S3 for storing the processed data.
** Amazon SageMaker for real-time forecasting of energy usage.

* AWS Lambda to query the partitioned business data through Amazon Athena or invoke SageMaker to provide API query results.
* Amazon API Gateway to deliver API query results for energy usage, anomalies, and meter outages.

